\chapter{E-Rechnungsstandards und Compliance}
\label{chap:standards_compliance}

Nicht jede digitale Datei, die eine Rechnung darstellt, ist auch wirklich eine elektronische Rechnung im rechtlichen und technischen Sinne. Ein eingescanntes Papier oder ein aus Word exportiertes PDF ist zwar für Menschen lesbar, für Software aber nur ein Bild ohne strukturierten Inhalt. Erst wenn die Rechnungsdaten in einem maschinenlesbaren Format vorliegen, kann eine Software wie der \textit{SmartBillConverter} diese automatisch verarbeiten.

Dieses Kapitel erklärt die zwei für das Projekt wichtigen XML-basierten E-Rechnungsstandards — das österreichische \textit{ebInterface 6.1} und das deutsche Hybridformat \textit{ZUGFeRD 2.3} — sowie deren Bezug zur europäischen Norm EN 16931. Beide Standards lösen das gleiche Problem auf unterschiedliche Weise und haben dabei jeweils eigene Stärken und Schwächen.

\section{ebInterface 6.1 (Österreich)}
\label{sec:ebinterface}

\subsection{Zweck und Historie}
Unter der Trägerschaft der AUSTRIAPRO, einer Serviceeinrichtung der Wirtschaftskammer Österreich (WKO), entstand ebInterface als nationale Antwort auf die wachsende Nachfrage nach einem einheitlichen, XML-basierten Rechnungsaustausch. Der Entwicklungsbeginn in den frühen 2000er-Jahren spiegelte eine strukturelle Lücke wider: Während Großkonzerne auf komplexe EDI-Systeme zurückgreifen konnten, fehlte kleinen und mittleren Unternehmen ein zugängliches, breit akzeptiertes Dateiformat. Über aufeinanderfolgende Versionen (4.0, 5.0, 6.0) wurde das Schema bis zur gegenwärtig verbindlichen Version 6.1 weiterentwickelt.

Einen entscheidenden Verbreitungsschub erlebte ebInterface im Jahr 2014, als die verpflichtende elektronische Rechnungslegung gegenüber österreichischen Behörden gesetzlich verankert wurde. Seitdem ist ebInterface die Pflichtgrundlage für alle Rechnungen, die über das Unternehmensserviceportal (USP) eingereicht werden, was dazu geführt hat, dass das Format auch außerhalb des öffentlichen Sektors immer weiter verbreitet ist.\footnote{Vgl. AUSTRIAPRO: \textit{ebInterface - Der österreichische Standard für die elektronische Rechnung}, \url{https://www.ebinterface.at/}, letzter Zugriff am 19.12.2025}

\subsection{Kernelemente und Struktur}
Im Gegensatz zu ZUGFeRD enthält eine ebInterface-Datei kein lesbares PDF-Layout — sie ist ausschließlich eine XML-Datei mit den Rechnungsdaten. Wer eine ebInterface-Rechnung mit eigenen Augen lesen will, braucht entweder einen speziellen Viewer oder muss sie zuerst mit XSLT in ein lesbares Format umwandeln.

Die Struktur einer ebInterface 6.1 Datei ist hierarchisch aufgebaut und besteht aus folgenden Hauptbereichen:
\begin{itemize}
    \item \textbf{Root-Element}: \texttt{<Invoice>} definiert die Grundeigenschaften der Rechnung wie Währung, Sprache und Dokumententitel.
    \item \textbf{Header-Daten}: Enthält eine eindeutige Rechnungsnummer (\texttt{InvoiceNumber}), das Rechnungsdatum (\texttt{InvoiceDate}) und den Leistungszeitraum (\texttt{Delivery}).
    \item \textbf{Biller (Rechnungssteller)}: Beinhaltet detaillierte Informationen zum Rechnungssteller wie Anschrift, Kontaktdaten, Bankverbindung und die gesetzlich vorgeschriebenen UID-Nummer (VAT Identification Number).
    \item \textbf{InvoiceRecipient (Rechnungsempfänger)}: Analog zum Biller entählt dieser Bereich die Daten des Leistungsempfängers. Hier ist oft die Auftragsreferenz (Order Reference) besonders wichtig für die automatisierte Zuordnung der Rechnung.
    \item \textbf{Details (Positionen)}: Das Herzstück der Rechnung. Hier werden in einer Liste (\texttt{ItemList}) die einzelnen Positionen (\texttt{ListLineItem}) aufgeführt. Jede Position enthält Menge, Einheit, Beschreibung, Einzelpreis, Zeilensumme und Steuerreferenz.
    \item \textbf{Tax (Steuern)}: Eine Zusammenfassung der Steuerbeträge, sortiert nach Steuersätzen. Dies ist wichtig für die Prüfung des Vorsteuerabzugs.
    \item \textbf{PaymentConditions}: Beinhaltet Zahlungsziele, Fälligkeitsdaten und Skonto-Informationen.
\end{itemize}

\subsection{Pflichtfelder und Validierung}
Die Gültigkeit einer ebInterface-Rechnung wird durch ein XML Schema (XSD) definiert. Pflichtfelder sind die Angaben, die das Umsatzsteuergesetz (UStG) für eine ordnungsgemäße Rechnung vorschreibt. In Österreich gehören dazu unter anderem:
\begin{itemize}
    \item Name und Anschrift des empfangenden und liefernden Unternehmers.
    \item Menge und gebräuchliche Bezeichnung der Waren oder erbrachten Leistungen.
    \item Kalendertag der Lieferung oder Leistung.
    \item Entgelt (Netto) und der darauf hinfällige Steuerbetrag.
    \item Der anzuwendende Steuersatz.
    \item Ausstellungsdatum und fortlaufende Rechnungsnummer.
    \item UID-Nummer des Rechnungsstellers (und ab 10.000 Euro Brutto auch des Empfängers).
\end{itemize}

Auffällig bei ebInterface 6.1 ist die strenge Typ-Prüfung: Datumsfelder akzeptieren nur das ISO-8601-Format, Betragsfelder müssen Dezimalzahlen sein. Das ist bei der automatischen Generierung durch KI sehr nützlich, weil Fehler wie ein falsch formatiertes Datum (z.B. TT.MM.JJJJ statt JJJJ-MM-TT) sofort als XSD-Validierungsfehler auffallen, statt unbemerkt falsche Werte in die Rechnung einzubauen.

\subsection{Beispielhafte XML-Struktur}
Um die Struktur zu veranschaulichen, zeigt das folgende Beispiel einen gekürzten Ausschnitt einer validen ebInterface 6.1 Rechnung. Man erkennt deutlich die hierarchische Gliederung und die aussagekräftigen Tag-Namen, die eine Umsetzung erleichtern.

\begin{lstlisting}[language=XML, caption={Ausschnitt einer ebInterface 6.1 Rechnung}, label={lst:ebinterface_example}]
<Invoice xmlns="http://www.ebinterface.at/schema/6p1/" 
         GeneratingSystem="SmartBillConverter">
  <InvoiceNumber>2024-001</InvoiceNumber>
  <InvoiceDate>2024-01-15</InvoiceDate>
  <Delivery>
    <Date>2024-01-10</Date>
  </Delivery>
  <Biller>
    <VATIdentificationNumber>ATU12345678</VATIdentificationNumber>
    <Address>
      <Name>Musterfirma GmbH</Name>
      <Street>Hauptstrasse 1</Street>
      <Town>Wien</Town>
      <ZIP>1010</ZIP>
      <Country>Austria</Country>
    </Address>
  </Biller>
  <Details>
    <ItemList>
      <ListLineItem>
        <Description>Software Entwicklung</Description>
        <Quantity Unit="h">10.00</Quantity>
        <UnitPrice>100.00</UnitPrice>
        <TaxItem>
          <TaxPercent>20</TaxPercent>
        </TaxItem>
        <LineItemAmount>1000.00</LineItemAmount>
      </ListLineItem>
    </ItemList>
  </Details>
  <Tax>
    <VAT>
      <TaxedAmount>1000.00</TaxedAmount>
      <TaxPercent>20</TaxPercent>
      <Amount>200.00</Amount>
    </VAT>
  </Tax>
  <TotalGrossAmount>1200.00</TotalGrossAmount>
</Invoice>
\end{lstlisting}

Was an diesem Beispiel auffällt: Die Einzelpositionen im \texttt{Details}-Block und die Steuerberechnung im \texttt{Tax}-Block müssen rechnerisch übereinstimmen. Genau das ist bei der KI-basierten Generierung das häufigste Problem, weil LLMs solche Berechnungen nicht zuverlässig selbst durchführen.

\section{ZUGFeRD 2.3 und EN 16931 (Deutschland/EU)}
\label{sec:zugferd}

\subsection{Das hybride Konzept}
ZUGFeRD, entwickelt vom \textit{Forum elektronische Rechnung Deutschland (FeRD)}, funktioniert ganz anders als reine XML-Formate wie ebInterface. Statt einer eigenständigen XML-Datei wird eine ganz normale PDF-Rechnung erstellt, in die die XML-Daten unsichtbar eingebettet werden. Technisch gesehen ist das eine PDF/A-3-Datei, die eine XML-Datei (meistens \texttt{factur-x.xml} oder \texttt{zugferd-invoice.xml}) als versteckten Anhang enthält.

Durch diese Dualität entsteht ein Format mit zwei unabhängig nutzbaren Informationsschichten:
\begin{itemize}
    \item \textbf{Visuelle Ebene}: Das PDF-Rendering entspricht dem gewohnten Rechnungslayout und ist ohne Spezialsoftware lesbar.
    \item \textbf{Strukturierte Datenschicht}: Das eingebettete XML liefert dieselben Informationen in maschinenverarbeitbarer Form.
\end{itemize}
Diese Architekturentscheidung löst ein in der Praxis häufig auftretendes Akzeptanzproblem: Empfänger ohne automatisierte Verarbeitungsinfrastruktur behandeln ZUGFeRD-Dokumente schlicht als gewöhnliche PDFs, während systemseitig die XML-Nutzlast selektiv extrahiert und weiterverarbeitet werden kann.

\subsection{Profile und Konformität}
ZUGFeRD 2.3 setzt die europäische Norm EN 16931 um. Da die Anforderungen je nach Unternehmensgröße und Branche variieren, definiert ZUGFeRD verschiedene Profile:

\begin{enumerate}
    \item \textbf{MINIMUM}: Enthält nur grundlegende Daten, um eine Buchungshilfe zu bieten. Es erfüllt nicht die Anforderungen einer steuerrechtlich gültigen Rechnung.
    \item \textbf{BASIC WL (Without Lines)}: Enthält Kopfdaten und Summen, jedoch keine einzelnen Positionsdaten. Nützlich für einfache Verbuchung, aber eingeschränkt in der Prüfung.
    \item \textbf{BASIC}: Erfüllt die Anforderungen des deutschen UStG für Rechnungen unter bestimmten Grenzen, stellt aber eine nur einen kleinen Teil der EN 16931 dar.
    \item \textbf{EN 16931 (COMFORT)}: Das Standardprofil, welches die europäische Norm vollständig abbildet und für den grenzüberschreitenden Verkehr als auch für B2G (Business to Government) geeignet ist. Dies ist das Zielformat für den \textit{SmartBillConverter}.
    \item \textbf{EXTENDED}: Ergänzt erweiterte branchenspezifische Erweiterungen, die über die Norm hinausgehen.
\end{enumerate}

\subsection{CII-Struktur (Cross Industry Invoice)}
Für die XML-Struktur verwendet ZUGFeRD das \textit{Cross Industry Invoice} (CII) Schema der UN/CEFACT. Dieser Standard wurde eigentlich für komplexe globale Lieferketten entwickelt und ist daher für eine einfache Rechnung deutlich umfangreicher als nötig. Ein gutes Beispiel: Ein einfacher Einzelpreis ist in CII kein einfacher Zahlenwert, sondern ein ganzes Objekt mit Betrag, Währung, Basismenge und Einheitencode als separate Felder.

Beispielhafte Verschachtelung in CII:
\texttt{SupplyChainTradeTransaction} $\rightarrow$ \texttt{IncludedSupplyChainTradeLineItem} $\rightarrow$ \texttt{SpecifiedLineTradeAgreement} $\rightarrow$ \texttt{NetPriceProductTradePrice} $\rightarrow$ \texttt{ChargeAmount}.
Diese hohe Komplexität macht die Implementierung eines Mappers anspruchsvoll, da hunderte von Pfaden korrekt ausgefüllt werden müssen, um Validierungsfehler zu vermeiden.\footnote{Vgl. FeRD e.V.: \textit{ZUGFeRD 2.3 - Das Datenformat für elektronische Rechnungen}, \url{https://www.ferd-net.de/standards/zugferd-2.3/index.html}, letzter Zugriff am 19.12.2025}
Das folgende Beispiel stellt ein Ausschnitt einer ZUGFeRD-XML dar, der die Komplexität im Vergleich zu ebInterface verdeutlicht. Es sollten die tiefen Verschachtelungen für einfache Informationen wie den Steuerbetrag beachtet werden.

\begin{lstlisting}[language=XML, caption={Ausschnitt einer ZUGFeRD 2.3 (CII) Rechnung}, label={lst:zugferd_example}]
<rsm:CrossIndustryInvoice xmlns:rsm="urn:un:unece:uncefact:data:standard:CrossIndustryInvoice:100" ...>
  <rsm:SupplyChainTradeTransaction>
    <ram:IncludedSupplyChainTradeLineItem>
      <ram:SpecifiedLineTradeAgreement>
        <ram:NetPriceProductTradePrice>
          <ram:ChargeAmount>100.00</ram:ChargeAmount>
        </ram:NetPriceProductTradePrice>
      </ram:SpecifiedLineTradeAgreement>
      <ram:SpecifiedLineTradeSettlement>
        <ram:ApplicableTradeTax>
          <ram:TypeCode>VAT</ram:TypeCode>
          <ram:CategoryCode>S</ram:CategoryCode>
          <ram:RateApplicablePercent>19.00</ram:RateApplicablePercent>
        </ram:ApplicableTradeTax>
      </ram:SpecifiedLineTradeSettlement>
    </ram:IncludedSupplyChainTradeLineItem>
    <ram:ApplicableHeaderTradeSettlement>
      <ram:SpecifiedTradeSettlementHeaderMonetarySummation>
        <ram:LineTotalAmount>100.00</ram:LineTotalAmount>
        <ram:TaxBasisTotalAmount>100.00</ram:TaxBasisTotalAmount>
        <ram:TaxTotalAmount currencyID="EUR">19.00</ram:TaxTotalAmount>
        <ram:GrandTotalAmount>119.00</ram:GrandTotalAmount>
      </ram:SpecifiedTradeSettlementHeaderMonetarySummation>
    </ram:ApplicableHeaderTradeSettlement>
  </rsm:SupplyChainTradeTransaction>
</rsm:CrossIndustryInvoice>
\end{lstlisting}
\section{UBL vs. CII: Mapping-Überlegungen und Trade-offs}
\label{sec:ubl_cii}

Interessant ist, dass die Norm EN 16931 zwei völlig unterschiedliche XML-Formate als gleichwertig anerkennt: UBL (ISO/IEC 19845) und UN/CEFACT CII. Das liegt daran, dass verschiedene Länder und Netzwerke unterschiedliche Präferenzen haben. Peppol, das europaweite E-Procurement-Netzwerk, nutzt hauptsächlich UBL, während ZUGFeRD auf CII basiert. Das führt dazu, dass es in Europa kein einheitliches Format gibt.

\subsection{Strukturelle Unterschiede}
\textbf{UBL} hat für jeden Dokumenttyp ein eigenes Schema: eines für Bestellungen (\texttt{Order}), eines für Rechnungen (\texttt{Invoice}), eines für Lieferscheine (\texttt{DespatchAdvice}) usw. Das macht die Struktur übersichtlich und relativ einfach zu lesen. \textbf{CII} hingegen versucht alle möglichen Geschäftsprozesse in einem einzigen Schema abzubilden, wobei eine Rechnung dann nur ein Sonderfall von Lieferkettenoperationen ist. Das macht CII mächtiger, aber auch deutlich komplizierter.

Ein konkretes Beispiel ist die Handhabung von Steuern:
\begin{itemize}
    \item In \textbf{UBL} werden Steuern häufig direkt auf Zeilenebene referenziert (\texttt{ClassifiedTaxCategory}).
    \item In \textbf{CII} gibt es komplexe \texttt{ApplicableTradeTax}-Strukturen, die sowohl auf Dokumentenebene (Summen) als auch auf Zeilenebene (Referenzen) übereinstimmend geführt werden müssen.
\end{itemize}

\subsection{Herausforderungen für den Konverter}
Für den \textit{SmartBillConverter} bedeutet das eine wichtige Anforderung: Das interne Datenmodell darf nicht zu eng an ebInterface angelehnt sein, weil sonst die Umwandlung nach CII sehr schwierig wird. ebInterface fasst zum Beispiel alle Rechnungsstellerdaten unter einem einzigen \textit{Biller}-Element zusammen, während CII die gleichen Daten auf viele Container wie \textit{SupplyChainTradeTransaction} verteilt. Ein direktes Mapping von ebInterface auf CII würde zu sehr unübersichtlichem Code führen.

Die Lösung war, ein eigenes internes C\#-Objekt als Zwischenschritt zu verwenden. Die KI befüllt dieses Objekt mit den extrahierten Daten, und danach wird es von separaten Klassen in das jeweilige Zielformat (ebInterface oder ZUGFeRD) umgewandelt.
Tabelle \ref{tab:format_comparison} fasst die bedeutenden Unterschiede zusammen, die bei der Umsetzung beachtet wurden.

\begin{table}[h]
    \centering
    \begin{tabular}{|p{4cm}|p{5cm}|p{5cm}|}
    \hline
    \textbf{Merkmal} & \textbf{ebInterface 6.1} & \textbf{ZUGFeRD 2.3 (CII)} \\
    \hline
    Basis-Standard & National (AUSTRIAPRO) & International (UN/CEFACT) \\
    \hline
    Dateiformat & Reines XML & PDF/A-3 mit eingebettetem XML \\
    \hline
    Struktur-Tiefe & Flach bis Mittel & Sehr tief verschachtelt \\
    \hline
    Steuer-Logik & Zentraler Tax-Block & Verteilt (Line & Header) \\
    \hline
    Pflichtfelder & Fokus auf UStG (AT) & Fokus auf EN 16931 (EU) \\
    \hline
    Visualisierung & Benötigt Stylesheet & PDF ist menschenlesbar \\
    \hline
    \end{tabular}
    \caption{Vergleich zwischen ebInterface und ZUGFeRD}
    \label{tab:format_comparison}
\end{table}
\section{XSD-Validierung vs. Geschäftsregeln (BR-S-08 etc.)}
\label{sec:validation}

Ein XML-Dokument kann technisch korrekt aufgebaut sein und trotzdem falsche Inhalte haben. Gerade bei der automatischen Generierung durch KI ist das ein häufiges Problem. Im \textit{SmartBillConverter} werden deshalb beide Arten von Fehlern getrennt geprüft.

\subsection{Syntaktische Validierung (XSD)}
Das XSD (XML Schema Definition) des jeweiligen Standards beschreibt genau, wie das XML aufgebaut sein muss. Es legt fest, welche Felder vorhanden sein müssen, in welcher Reihenfolge sie kommen dürfen und welchen Datentyp sie haben sollen. Typische Prüfpunkte sind:
\begin{itemize}
    \item Vollständigkeit der obligatorischen Felder?
    \item Korrektheit des Datumsformats (strikt ISO 8601: YYYY-MM-DD)?
    \item Numerische Typen ohne unerlaubte String-Repräsentationen?
    \item Einhaltung der Elementreihenfolge \textemdash{} insbesondere CII toleriert keinerlei Abweichungen.
\end{itemize}
Ein Dokument, das diesen syntaktischen Vertrag verletzt, wird von konformen Empfangssystemen in aller Regel bereits beim Einlesen verworfen, ohne dass eine inhaltliche Prüfung auch nur beginnt.

\subsection{Semantische Validierung (Business Rules)}
Nur weil das XML technisch korrekt aufgebaut ist, heißt das noch nicht, dass die Inhalte auch stimmen. Deshalb legt die Norm EN 16931 zusätzlich eine Liste von Geschäftsregeln fest, die sicherstellen sollen, dass die Beträge und Steuern rechnerisch korrekt und widerspruchsfrei sind. Diese Regeln werden meistens mit \textit{Schematron} geprüft.

Ein prominentes und im Projektverlauf problematisches Beispiel ist die Regel \textbf{BR-S-08} (Value Added Tax Breakdown).
Diese Regel besagt: \textit{Für jeden unterschiedlichen Steuercode und Steuersatz, der in den Rechnungspositionen verwendet wird, muss genau eine Zusammenfassung auf Dokumentenebene existieren, und die Summe der Steuerbeträge muss rechnerisch korrekt sein.}

Das Problem bei der Generierung durch KI ist, dass LLMs keine Taschenrechner sind. Sie schätzen auf Basis von Wahrscheinlichkeiten den nächsten Token, anstatt wirklich zu rechnen. In der Praxis heißt das: Ein LLM kann eine plausibel aussehende, aber falsche Steuersumme ausgeben, weil es den Wert errät statt ihn zu berechnen:
\begin{itemize}
    \item Position 1: 100 Euro, 20\% MwSt
    \item Position 2: 200 Euro, 20\% MwSt
    \item Steuer-Summe: 55 Euro (statt korrekt 60 Euro)
\end{itemize}
Das LLM "schätzt" oder "halluziniert" die Summe oft, anstatt sie zu berechnen.
Deshalb wurde im \textit{SmartBillConverter} eine klare Aufgabenteilung eingebaut: Die KI liefert nur die Einzelwerte (Einzelbeträge, Steuersätze, Mengen), während alle Summen, Rundungen und Steuerberechnungen fest im C\#-Backend berechnet werden. Nur so kann sichergestellt werden, dass die Regel BR-S-08 immer korrekt eingehalten wird.\footnote{Vgl. CEN - European Committee for Standardization: \textit{EN 16931-1:2017 Electronic invoicing - Semantic data model}, \url{https://standards.cen.eu/dyn/www/f?p=204:110:0::::FSP_PROJECT:60602&cs=1B61B766636F9FB34B7DBD72CE9026C72}, letzter Zugriff am 19.12.2025}

\chapter{Dokumentenverarbeitung und KI-Grundlagen}
\label{chap:doc_processing_ai}

Die automatische Verarbeitung von Rechnungen ist ein altbekanntes Problem. Frühere Systeme haben meistens mit Templates gearbeitet: Für jeden Lieferanten wurde manuell festgelegt, an welcher Stelle im Dokument zum Beispiel die Rechnungsnummer steht. Sobald sich das Layout auch nur minimal ändert, hört so ein System auf zu funktionieren. Der \textit{SmartBillConverter} geht deshalb einen anderen Weg und verwendet Large Language Models (LLMs), die das Layout eines Dokuments selbstständig verstehen können. Die folgenden Abschnitte erklären die dafür nötigen technischen Grundlagen.

\section{PDFs und Textextraktion}
\label{sec:pdf_extraction}

\subsection{Die Natur des PDF-Formats}
PDFs sind keine Textdokumente mit Layoutinformationen \textemdash{} sie sind Renderinganweisungen, die zufällig auch Text enthalten können. Das Format speichert primär geometrische Befehle vom Typ ,,Zeichne Glyphe A an Koordinate (100,\,200) in Schrift Helvetica 12\,pt``. Ob dieses A zum Wort ,,Rechnungsnummer`` gehört, ob dieses Wort eine Tabellenüberschrift ist oder ob die nachfolgende Zahl einen Netto- oder Bruttobetrag darstellt \textemdash{} all das ist im PDF-Stream nicht kodiert und muss von Extraktionssoftware heuristisch erschlossen werden.

Für die Textextraktion ergeben sich daraus massive Probleme:
\begin{itemize}
    \item \textbf{Verlust der Lesereihenfolge}: In einem PDF-Stream können die Zeichenbefehle in beliebiger Reihenfolge stehen. Ein zweispaltiger Text kann im Stream so gespeichert sein, dass erst die erste Zeile der linken Spalte, dann die erste Zeile der rechten Spalte kommt. Ein naiver Extraktor liest dann "Rechnungs Datum: 01.01.2024" als "Rechnungs 01.01.2024 Datum:".
    \item \textbf{Fehlende Wortgrenzen}: Oft werden Wörter nicht als String gespeichert, sondern jeder Buchstabe einzeln positioniert (Kerning). Leerzeichen sind oft gar keine Zeichen, sondern einfach Lücken in den Koordinaten.
    \item \textbf{Encoding-Probleme}: Manchmal nutzen PDFs benutzerdefinierte Encodings, sodass der Buchstabe "A" im Code als "X" gespeichert ist, aber visuell als "A" dargestellt wird. Ohne korrekte ToUnicode-Map ist nur "Datensalat" extrahierbar.
\end{itemize}

\subsection{Lösungsansatz mit PdfPig}
Um dieses Problem zu lösen, wird die .NET-Bibliothek \textit{PdfPig} verwendet. Sie analysiert die genauen Koordinaten jedes einzelnen Buchstabens im PDF und versucht daraus die richtige Lesereihenfolge zu rekonstruieren. Buchstaben, die dicht nebeneinander auf gleicher Höhe liegen, werden zu Wörtern zusammengefügt, und Wörter auf der gleichen Linie bilden dann eine Textzeile.
Besonders schwierig sind dabei Tabellen: Die Linien einer Tabelle im PDF sind nur gewöhnliche Vektorgrafiken ohne Verbindung zum Text. Deshalb kann die Software oft nicht erkennen, welche Zahl zu welcher Spalte gehört. Trotzdem ist diese direkte Textextraktion aus dem PDF deutlich besser als OCR, weil dabei keine Buchstabenverwechslungen wie bei ,,8`` und ,,B`` passieren können.\footnote{Vgl. UglyToad: \textit{PdfPig - Read and extract text and other content from PDFs in C\# (port of PdfBox)}, \url{https://github.com/UglyToad/PdfPig}, letzter Zugriff am 19.12.2025}

\section{OCR mit Tesseract}
\label{sec:ocr}

Liegt eine Rechnung nicht als nativ-digitales PDF vor \textemdash{} sei es als Scan einer physischen Vorlage oder als fotografische Aufnahme \textemdash{} liefert jede koordinatenbasierte Textextraktion ein leeres Ergebnis. Der Inhalt existiert in diesen Fällen ausschließlich als Pixelmuster, das erst durch Optical Character Recognition (OCR) in maschinenlesbaren Text überführt werden muss.

\subsection{Funktionsweise von Tesseract}
Als OCR-Engine wird \textit{Tesseract} verwendet, ein Open-Source-Projekt das ursprünglich von HP entwickelt wurde und heute von Google weiterentwickelt wird. Ab Version 4.0 basiert Tesseract auf LSTM-Netzen (Long Short-Term Memory), einer Art neuronalem Netz das gut mit sequenziellen Daten wie Text umgehen kann. Dadurch erkennt es Buchstaben deutlich zuverlässiger als ältere regelbasierte Methoden.
Die Verarbeitung läuft grob in vier Schritten ab:
\begin{enumerate}
    \item \textbf{Layout-Analyse}: Identifikation von Textregionen, Spalten und Zeilen im Bild.
    \item \textbf{Baseline-Fitting}: Erkennen der Grundlinie jeder Textzeile \textemdash{} wichtig damit Buchstaben richtig segmentiert werden können, auch wenn der Scan leicht schief ist.
    \item \textbf{Zeichenerkennung}: Das LSTM-Netz analysiert kleine Bildausschnitte und ordnet ihnen Buchstaben mit einem Konfidenzwert zu.
    \item \textbf{Worterkennung}: Wörterbücher helfen dabei, dass die erkannten Zeichenfolgen auch sinnvolle Wörter ergeben.
\end{enumerate}

\subsection{Einflussfaktoren auf die Qualität}
Die erzielte Erkennungsqualität hängt dabei in erheblichem Maß von der Eingabequalität und vorgeschalteter Bildaufbereitung ab:
\begin{itemize}
    \item \textbf{Auflösung}: Unter 300 DPI wird die Erkennungsrate deutlich schlechter, weil die feinen Linien einzelner Buchstaben zu wenige Pixel haben um sicher erkannt zu werden.
    \item \textbf{Binarisierung}: Das Umwandeln in Schwarz-Weiß muss bei ungleichmäßiger Beleuchtung oder Schatten adaptiv erfolgen, also für verschiedene Bildbereiche getrennt berechnet werden, statt einen einzigen fixen Schwellwert für das gesamte Bild zu verwenden.
    \item \textbf{Geraderichten (Deskewing)}: Selbst eine Drehung um nur zwei Grad reicht aus, damit Tesseract die Textzeilen nicht mehr richtig findet. Scans müssen deshalb immer rechnerisch gerade gerückt werden.
\end{itemize}
Im Projekt werden die deutschsprachigen Trainingsdaten (\texttt{deu.traineddata}) geladen, da österreichische Rechnungen spezifische Vokabeln und Umlaute enthalten, deren fehlerhafte Erkennung nachgelagerte Extraktionsschritte unverhältnismäßig stark beeinträchtigt. Die verbleibende Fehlerquote wird durch die anschließende LLM-Korrekturschicht aufgefangen.

\section{LLMs für Informationsextraktion}
\label{sec:llm_extraction}

Der größte Unterschied zu älteren Ansätzen ist, dass kein Entwickler mehr für jedes mögliche Rechnungslayout eigene Erkennungsregeln schreiben muss. Stattdessen wird einfach der gesamte Text der Rechnung an das LLM übergeben, und das Modell strukturiert die Daten selbstständig in das gewünschte Format.

\subsection{Architektur und Funktionsweise}
Moderne LLMs basieren auf der Transformer-Architektur und verwenden Attention-Mechanismen, um Zusammenhänge zwischen verschiedenen Teilen eines Textes zu erkennen. Wichtig für die Extraktion ist das sogenannte \textit{In-Context Learning}: Das Modell wurde zwar nie speziell auf Rechnungen trainiert, hat aber durch sein allgemeines Training gelernt, dass eine IBAN meistens bei Wörtern wie ,,Bankverbindung`` oder ,,Kontonummer`` steht.
Außerdem kann das Modell Synonyme automatisch auflösen: Ob auf der Rechnung ,,Total``, ,,Zahlbetrag``, ,,Rechnungssumme`` oder ,,zu zahlender Betrag`` steht \textemdash{} das Modell erkennt in allen Fällen, dass dasselbe Feld \texttt{TotalAmount} gemeint ist.

\subsection{Modell-Vergleich und Evaluation}
Im Rahmen der Entwicklung wurden verschiedene Modelle evaluiert (siehe Projektdokumentation):
\begin{itemize}
    \item \textbf{Gemini 2.5 Flash}: Ein sehr schnelles und kosteneffizientes Modell von Google. Es zeigte im Projekt die beste Balance aus Geschwindigkeit und JSON-Konformität. Es hat ein großes Kontextfenster, was für lange Rechnungen wichtig ist.
    \item \textbf{Mistral (verschiedene Größen)}: Open-Source-Modelle, die lokal oder via API laufen können. Während große Modelle (Mistral Large) gut performen, neigen kleinere Modelle (7B) dazu, das JSON-Schema zu verletzen oder komplexe Tabellen zu halluzinieren.
    \item \textbf{Qwen}: Ein starkes Modell, das jedoch im Test oft Prompt-Logging und Training erforderte, was Datenschutzbedenken aufwirft.
\end{itemize}

\subsection{Risiken: Halluzinationen}
Das größte Problem bei LLMs ist die Halluzination. LLMs sind so trainiert, dass sie immer eine möglichst sinnvolle Antwort generieren. Wenn auf einer Rechnung zum Beispiel kein Lieferdatum steht, das JSON-Schema aber eines erwartet, dann erfindet das Modell einfach ein Datum \textemdash{} meistens das Rechnungsdatum.
Für eine Finanzanwendung ist das ein ernstes Problem, weil ein erfundenes Lieferdatum in einer archivierten Rechnung steuerrechtliche Folgen haben kann. Der Prompt muss deshalb das Modell klar anweisen, in solchen Fällen \texttt{null} zurückzugeben statt zu raten.

\section{Prompt-Design für deterministische Ausgabe}
\label{sec:prompt_design}

Prompt Engineering bedeutet, die Eingabe an das Modell so zu formulieren, dass man die gewünschten Ergebnisse bekommt. Bei der Datenextraktion geht es dabei nicht um Kreativität, sondern darum, dass das Modell bei gleicher Eingabe immer die gleiche Ausgabe liefert.

\subsection{Techniken}
\begin{itemize}
    \item \textbf{System Prompting}: Am Anfang des Prompts wird dem Modell eine klare Rolle gegeben, z.B.: ,,Du bist ein Datenextraktions-Assistent. Antworte ausschließlich mit einem gültigen JSON-Objekt, ohne zusätzlichen Text.``
    \item \textbf{JSON Mode / Structured Output}: Moderne APIs wie Google Gemini oder OpenAI bieten einen speziellen Modus an, bei dem die Antwort des Modells immer gültiges JSON ist. Das ist zuverlässiger als einfach im Prompt darum zu bitten.
    \item \textbf{Schema Injection}: Das Ziel-JSON-Schema wird als Teil des Prompts übergeben, sodass das Modell die erwarteten Feldnamen, Typen und Pflichtfelder als Kontext erhält.
    \item \textbf{Chain-of-Thought Unterdrückung}: Bei manchen Aufgaben hilft es, das Modell Schritt für Schritt denken zu lassen. Bei der Datenextraktion ist das aber hinderlich, weil das Modell dann Erklärungen in die Antwort mischt. Mit der Anweisung ,,Keine Erklärungen, nur das JSON-Objekt`` wird das verhindert.
\end{itemize}

Ein Beispiel für ein solches JSON-Schema, wie es im \textit{SmartBillConverter} verwendet wird, zeigt Listing \ref{lst:json_schema}. Es definiert strikte Typen für die Extraktion.

\begin{lstlisting}[language=json, caption={JSON-Schema für die KI-Extraktion}, label={lst:json_schema}]
{
  "type": "object",
  "properties": {
    "invoiceNumber": { "type": "string" },
    "invoiceDate": { "type": "string", "format": "date" },
    "totalAmount": { "type": "number" },
    "currency": { "type": "string", "enum": ["EUR", "USD"] },
    "items": {
      "type": "array",
      "items": {
        "type": "object",
        "properties": {
          "description": { "type": "string" },
          "quantity": { "type": "number" },
          "unitPrice": { "type": "number" },
          "taxRate": { "type": "number" }
        }
      }
    }
  },
  "required": ["invoiceNumber", "invoiceDate", "totalAmount", "items"]
}
\end{lstlisting}

Ein konkretes Problem war, dass dasselbe Modell beim gleichen Prompt manchmal unterschiedliche Ergebnisse geliefert hat \textemdash{} zum Beispiel Daten mal im Format YYYY-MM-DD und mal als DD.MM.YYYY. Das lässt sich durch genaue Formatierungsanweisungen im Prompt (,,Alle Daten im Format YYYY-MM-DD``) und die Einstellung Temperature\,=\,0 beheben, weil das Modell dann immer den wahrscheinlichsten Wert auswählt und die Ausgabe stabiler wird.

\section{Datenschutz und Sicherheit in KI-APIs}
\label{sec:ai_security}

Rechnungen enthalten viele sensible Informationen: personenbezogene Daten wie Namen, Adressen und UID-Nummern, aber auch Geschäftsinterna wie Preise, Lieferanten und Projektbezeichnungen. Wenn diese Daten an eine Cloud-KI-API geschickt werden, verlassen sie die eigene Infrastruktur \textemdash{} was aus Datenschutzsicht problematisch ist.

\subsection{Risikoanalyse}
\begin{itemize}
    \item \textbf{Modelltraining auf Kundendaten}: Ohne einen speziellen Enterprise-Vertrag können Anbieter wie Google oder OpenAI die eingesendeten Anfragen für das Training ihrer Modelle verwenden. Im normalen Tarif ist das erlaubt, im Enterprise-Tarif wird es vertraglich ausgeschlossen.
    \item \textbf{Daten im Klartext beim Anbieter}: Auch wenn die Übertragung per TLS verschlüsselt ist, muss der Anbieter die Daten für die Verarbeitung entschlüsseln. Kurzzeitig liegen die Rechnungsdaten also im Klartext auf den Servern des Anbieters. Bei einem lokal betriebenen Modell fällt dieses Risiko weg.
    \item \textbf{Rechtliche Unsicherheit}: US-Anbieter fallen unter den CLOUD Act, der amerikanischen Behörden bestimmte Zugriffmöglichkeiten gibt, selbst wenn die Daten auf europäischen Servern gespeichert sind. Das EU-US Data Privacy Framework, das solche Datentransfers regelt, ist außerdem politisch unsicher und wurde schon mehrfach vor Gericht angefochten.
\end{itemize}

\subsection{Lokale Alternativen}
Eine datenschutzfreundliche Alternative wäre, ein Open-Source-Modell wie Llama\,3 oder Mistral lokal auf eigener Hardware zu betreiben, zum Beispiel mit dem Tool Ollama. Dann verlassen die Rechnungsdaten nie die eigene Infrastruktur.
Der Nachteil ist, dass lokale Modelle deutlich mehr Hardware-Ressourcen brauchen. Für mehrseitige Rechnungen mit viel Text werden große Modelle mit 70B+ Parametern benötigt, die ohne eine leistungsstarke GPU sehr langsam sind. Kleinere Modelle mit 7B oder 13B Parametern liefern bei komplexen Rechnungen oft zu schlechte Ergebnisse.
Für den \textit{SmartBillConverter} wurde deshalb die Cloud-API von Gemini gewählt, weil die Qualität besser ist und die Entwicklung damit schneller geht. Für einen richtigen Produktivbetrieb müsste man aber auf einen Enterprise-Tarif mit entsprechenden Datenschutzgarantien umsteigen.
